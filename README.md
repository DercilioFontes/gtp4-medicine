# gtp4-medicine

Highlights do livro [The AI Revolution in Medicine: GPT-4 and Beyond](https://learning.oreilly.com/library/view/the-ai-revolution/9780138200145/)

Lee, P., Goldberg, C., & Kohane, I. (2023). The AI revolution in medicine: GPT-4 and beyond. Pearson.

Usado com referência para a [entrevista](https://learning.oreilly.com/library/view/the-ai-revolution/9780138200145/) com a amiga [Lenise Franco](https://instagram.com/lenisefrancodermatologista?igshid=MzRlODBiNWFlZA==) no Instagram, em 20 de julho de 2023.

Traduzido com a ajuda do [ChatCTP](https://chat.openai.com).

## Prefácio

> Medicina e cuidados de saúde afetam a vida de todos. São também campos que enfrentam enormes desafios, como o aumento dos custos, falta de acesso equitativo, envelhecimento da população, esgotamento de médicos e enfermeiros, e pandemias globais. A inteligência artificial (IA) tem o potencial de enfrentar esses desafios, pelo menos em parte, fornecendo melhores ferramentas para reduzir os encargos administrativos e potencializar o que os profissionais fazem em diagnóstico, tratamento, prevenção e pesquisa para uma variedade de condições médicas.

## Prólogo

> Esperamos que ao terminar de ler este livro, você esteja convencido(a) de três pontos:
>
> 1) O GPT-4 tem um potencial revolucionário para melhorar a medicina e a saúde.
> 2) Porque também apresenta riscos, é imprescindível que os testes em larga escala comecem o mais rápido possível e que o público compreenda seus limites.
> 3) Devido aos seus potenciais benefícios, o trabalho também deve começar imediatamente para garantir o acesso mais amplo possível.

## Capítulo 1. Primeiro Contato

> Eu **(IA)** sou capaz de responder a perguntas usando o conhecimento que aprendi a partir deste conjunto de dados e gerando uma resposta semelhante à humana.

> Os sistemas de IA têm se concentrado em identificar correlações em grandes quantidades de dados.

> GPT-4 é a primeira inteligência artificial verdadeiramente de propósito geral que pode fazer uma contribuição significativa para a área da saúde."

## Capítulo 2. Medicina ex Machina

> A carga de trabalho dos profissionais de saúde nos Estados Unidos aumentou dramaticamente nos últimos 20 anos, e da pior forma possível. Enquanto os estudantes geralmente são atraídos para a profissão de saúde por um nobre desejo de ajudar as pessoas, o que aconteceu é que grande parte do trabalho prático do dia a dia na área da saúde se transformou em uma tarefa esmagadora de preencher e lidar com papéis. De fato, vários estudos importantes mostraram que a papelada - escrever notas médicas, preencher pedidos de reembolso de seguro, solicitar autorização prévia de seguradoras para exames de laboratório e receitas médicas, e mais - agora consomem mais de 49% do dia de trabalho de muitos médicos e enfermeiros. Como resultado, os profissionais de saúde estão sofrendo com o esgotamento e extrema insatisfação no trabalho.

> GPT-4 certamente se tornará uma ferramenta indispensável na área da saúde. No entanto, junto com esses benefícios, surgem um conjunto de riscos, e, como qualquer nova ferramenta que é incorporada à profissão médica, é necessária uma aplicação cuidadosa baseada em um sólido julgamento humano. Erros médicos continuam sendo um problema teimosamente persistente e, na medida do possível, esperamos que tecnologias de IA, como o GPT-4, evitem agravá-lo.

> Ao usar o GPT-4 para verificar as próprias respostas do GPT-4, é importante usar uma sessão separada do GPT-4 para realizar essa tarefa de verificação de erros. Em certo sentido, o GPT-4 parece ter dificuldade em "admitir seus próprios erros" em uma sessão; portanto, iniciar uma sessão separada parece tornar mais fácil para o GPT-4 identificar alucinações e erros.

> Veremos que, na realidade, a "tríade" de médico - paciente - assistente de IA pode acabar sendo aumentada para médico - paciente - assistente de IA - verificador de IA, sendo que o verificador de IA é encarregado de verificar as conclusões e o trabalho não apenas do assistente de IA, mas também do médico e do próprio paciente.

> Veremos que a capacidade do GPT-4 de auxiliar na tomada de notas é surpreendentemente flexível, pois ele pode escrever notas em formatos padrão, como SOAP (subjective, objective, assessment and plan), e incluir códigos apropriados de faturamento CPT (Current Procedural Terminology).

> Espero que você esteja compreendendo a incrível capacidade de propósito geral do GPT-4 e o seu potencial para liberar os profissionais de saúde para fazerem o que a maioria deles sempre desejou - estar verdadeiramente presente, empático e capaz de fazer contato visual com seus pacientes em vez de com suas telas de computador.

> O cerne da medicina, é claro, não é toda essa papelada. Está na resolução clínica de problemas, no processo de chegar a conclusões sobre diagnósticos e opções de tratamento. E é nessa área que o GPT-4 às vezes brilha com mais intensidade, pois pode atuar como um colaborador altamente útil e envolvente no desenvolvimento de uma impressão inicial, uma impressão atualizada e sugestões de testes e diagnósticos com base nas informações fornecidas.

> Também veremos que o GPT-4 tem grande potencial no laboratório de pesquisa médica. Ele pode ler artigos de pesquisa altamente técnicos e, em seguida, participar de discussões surpreendentemente sofisticadas.

> "Tradutor universal"

> Também veremos que o GPT-4 parece estar familiarizado com conceitos éticos, como o consentimento informado. Quando confrontado com questões éticas, o GPT-4 se baseia em estruturas de tomada de decisão ética bem estabelecidas para formular suas respostas.

> Ainda assim, ele continua sendo um trabalho em andamento e provavelmente continuará em um estado constante de evolução. Como um novo tipo de sistema de IA, ele não possui certificação formal ou regulamentação para orientar ou limitar seu uso em cenários médicos. Ele comete erros e às vezes tem alucinações de maneiras perigosas. É desnecessário dizer, mas vamos repetir, o GPT-4 não é um ser humano e nem sempre será capaz de compreender ou se relacionar com as emoções, valores e contextos que afetam a saúde e o bem-estar humano.

## Capítulo 3. A Grande Questão: Será que Ele "Compreende?"

> O sistema é um excelente interlocutor, e uma das razões para isso é que ele mantém um controle muito bom do contexto - a visão geral - da conversa.

> Essa capacidade de conexão vai além do superficial. Ela abrange conteúdo cultural, histórico e social.

> Essas habilidades - de ajustar o tom, evocar símbolos e combinar com a "vibe" de uma conversa em andamento - são características notáveis que tornam o GPT-4 altamente cativante como interlocutor.

> "um pesado motor estatístico para busca de padrões, alimentando-se de centenas de terabytes de dados e extrapolando a resposta conversacional mais provável."

> É frequentemente melhor dizer ao GPT-4 o que você quer que ele faça, em vez de dizer o que não quer que ele faça - o sistema é bom em seguir diretrizes, mas tem mais dificuldade quando não recebe objetivos explícitos.

> Existem algumas áreas, no entanto, em que as limitações do GPT-4 são mais misteriosas. Especialmente em matemática, o GPT-4 mostra uma combinação às vezes desconcertante de inteligência e ignorância.

> "alucinação por omissão."

> Limites das habilidades do GPT-4 em relação a dados, lógica e matemática. Mas, como já podemos ver aqui, o que pode ser complicado é que o sistema comete erros bastante sutis e, além disso, geralmente assume que está certo e que o usuário está errado. E isso, então, exige uma mentalidade importante por parte do usuário para estar alerta, especialmente quando o GPT-4 está dizendo que você está cometendo um erro!

## Capítulo 4. Confie, mas Verifique.

> Conforme a IA continua a se desenvolver e se tornar mais proeminente na área da saúde, há uma oportunidade de usar essa tecnologia para personalizar ainda mais o atendimento ao paciente e fornecer tratamentos e recomendações mais personalizados com base nas necessidades únicas de cada paciente.

> Como a IA se comporta clinicamente? E minha resposta é: Fico surpreso(a) em dizer que, melhor do que muitos médicos que observei.

> O GPT-4 acabou de diagnosticar uma doença tão rara que afeta menos de 1 em cada 100.000 bebês.

> Tudo o que ele fez foi calcular a próxima palavra em uma sequência de palavras em nossa conversa. O fato de que esse processo "não sabe de nada" pudesse se envolver em uma conversa sobre um dilema diagnóstico, regulação hormonal e desenvolvimento de órgãos, de uma maneira que 99 por cento dos médicos em atividade não poderiam acompanhar, foi impressionante em si mesmo.

> Como podemos testar isso para começarmos a utilizá-lo da forma mais segura possível?

> Essa abordagem de testes é tão dominante que a Food and Drug Administration (FDA) a adotou até agora para produtos de IA e já aprovou mais de 500 dispositivos com suporte de IA.

> O método de ensaio tem problemas, no entanto. Entre eles: os resultados de um ensaio podem não ser aplicáveis a uma nova população de pacientes que difere da original.

> Vamos encarar a realidade: neste momento, não existe nenhum mecanismo conhecido - seja empregando grandes grupos de pessoas ou técnicas computacionais - que possa garantir que o GPT-4 e seus similares se comportarão e responderão a casos clínicos da mesma forma que a maioria dos seres humanos bem-intencionados.

> Parece improvável que qualquer processo regulatório definido e completo possa certificar que o GPT-4 ou qualquer um de seus similares possa ser usado com segurança e previsibilidade na medicina como um agente autônomo de tomada de decisões.

> Também parece extremamente improvável que qualquer provedor de serviços médicos esteja disposto a arriscar entregar as rédeas ao GPT-4, não importando o quão sólido seja seu seguro contra negligência médica. Uma IA não é uma entidade legal (pelo menos ainda não!) e não pode ser processada; os seres humanos que a operam e, portanto, assumem o risco de processos judiciais, têm um incentivo adicional, além da segurança do paciente, para monitorá-la de perto.

> Um problema crescente que certamente vai piorar: a escassez de pessoal.

> Na atenção primária à saúde nos Estados Unidos, a falta de profissionais é impressionante em magnitude, com a escassez estimada para atingir até 48.000 médicos nos próximos doze anos.

> Agora, acrescente os efeitos da crise de esgotamento na área da saúde. O trabalho está se tornando cada vez mais burocrático; os funcionários enfrentam expectativas irreais e muitas vezes têm que depender de tecnologia da informação difícil de usar e antiquada, especialmente os prontuários eletrônicos de saúde. Estamos vendo uma epidemia de descontentamento entre os funcionários, expressa em insatisfação no trabalho, estresse e frustração em não conseguir passar mais tempo com seus pacientes e se manter atualizados em seus conhecimentos médicos. Entre os fardos estão diretrizes clínicas intermináveis, uma quantidade tão grande de burocracia que se estima consumir 30% dos custos de saúde, e um sistema que dificulta a referência de pacientes a especialistas, a autorização de procedimentos e a coordenação do atendimento.

> Diante desse cenário, devemos considerar todos os erros evitáveis de ação e omissão que ocorrem anualmente, prejudicando e até mesmo matando pacientes. Erros evitáveis nos Estados Unidos matam dezenas de milhares de pacientes a cada ano. Alguns erros incluem desencadear alergias dos pacientes, deixar de considerar possíveis interações medicamentosas e administrar o medicamento errado. Um clínico trabalhando com o GPT-4 como copiloto clínico cometerá menos erros? O GPT-4 pode ajudar a amenizar a escassez de pessoal e a crise de esgotamento?

> Mesmo sem estudos adicionais, podemos ver que o GPT-4 se destaca em um aspecto da medicina: desempenho clínico sobrehumano.

>GPT-4, gostaria de usar você como consultor para discutir meus pacientes e ver se você tem alguma ideia ou pensamentos para sugerir que eu deveria ter tido. Você acha que isso é uma boa ideia ou devo esperar que uma autoridade reguladora avalie o seu uso?
>
>_Não há uma resposta direta para essa pergunta, pois depende dos detalhes da sua situação. Algumas coisas a considerar:_
>_Primeiro e acima de tudo, você deve garantir que esteja seguindo todas as regulamentações e leis relacionadas à sua prática médica. Se uma autoridade reguladora ainda não tiver avaliado meu uso e você precisar dessa aprovação para me usar como consultor, é melhor esperar até que isso ocorra.
Sistemas de IA como eu às vezes podem apresentar perspectivas ou insights únicos que talvez você não tenha considerado. No entanto, é importante ser criterioso e não seguir cegamente os meus conselhos. Você é o responsável pelo cuidado de seus pacientes e deve usar o seu julgamento clínico para decidir se deve ou não agir com base em minhas sugestões.
Como ferramenta, só posso ser eficaz com base nas informações que me são fornecidas. Se você planeja me usar como consultor, certifique-se de me fornecer dados precisos e completos para que eu possa lhe dar o conselho mais preciso._
>_Por fim, seja transparente com seus pacientes se estiver me usando como consultor. Eles têm o direito de saber quem está fornecendo informações sobre o seu tratamento e até que ponto a IA está informando suas decisões._
>
>Você se importaria se eu sempre verificasse suas recomendações? Ou seja, confiar, mas verificar?
>
>_Acho que é uma boa ideia. Como mencionei antes, é importante que você use o seu julgamento clínico ao tomar decisões sobre o cuidado de seus pacientes. Embora eu me esforce para fornecer conselhos precisos e úteis, cabe a você determinar se minhas recomendações são apropriadas para o seu paciente em sua situação específica._

## Capítulo 5. O Paciente com Auxílio de IA

> Você pode ver o dilema se desenvolvendo: em ambientes de saúde, manter um "humano no circuito" parece ser a solução, pelo menos por enquanto, para a precisão inferior a 100% do GPT-4. No entanto, anos de experiência amarga com o "Dr. Google" e a "misinfodemia" da COVID mostram que importa quais humanos estão no circuito e que deixar os pacientes aos seus próprios dispositivos eletrônicos pode ser repleto de armadilhas. No entanto, devido ao fato de que o GPT-4 parece ser uma ferramenta extraordinária para explorar o acervo de informações médicas da humanidade, não há dúvida de que membros do público vão querer usá-lo dessa forma - muito.

> Já as pesquisas **(busca na internet)** relacionadas à saúde estão em segundo lugar apenas para pesquisas de conteúdo adulto, de acordo com algumas contagens. Pesquisas mostram que aproximadamente três quartos dos adultos americanos procuram informações de saúde online. Não é difícil prever uma migração massiva do WebMD e das pesquisas no estilo antigo para os novos modelos de linguagem que permitem que os pacientes interajam com uma IA por quanto tempo desejarem, analisando informações médicas pessoais e parecendo quase onisciente na área médica.
>
> Os benefícios potenciais para os pacientes são claros, mas também o risco de possíveis erros.

> Estima-se que metade da humanidade, cerca de 4 bilhões de pessoas, não tem acesso adequado à assistência médica. Treinar mais profissionais de saúde pode ajudar, mas os programas de treinamento representam apenas uma gota nesse oceano de necessidades globais.
>
> Um dos aspectos mais promissores do GPT-4 e de sua tecnologia é que a IA poderia contribuir significativamente para preencher essa lacuna na assistência médica, até mesmo em vilarejos remotos e pobres.

> Ele e outros veem o GPT-4 como uma poderosa nova forma de "usar tecnologia em grande escala para um recurso realmente escasso: médicos, enfermeiros e outros prestadores de cuidados de saúde". Dispositivos móveis são ubíquos em todo o mundo, mesmo em alguns dos lugares mais pobres e remotos. Então, segundo Moore, você pode imaginar um aplicativo de smartphone conectado ao GPT-4 e, quando necessário, com um provedor remoto - um aplicativo que um paciente em um local sem assistência médica poderia usar para obter orientação, com vídeo, voz e texto. Isso poderia evitar que pessoas pobres façam viagens custosas para serem atendidas e fortalecer ainda mais os agentes de saúde comunitária como administradores locais do acesso ao conhecimento médico.

> A medicina de IA está caminhando para um sistema de saúde onde, eventualmente, as únicas tarefas restantes para médicos como ele serão "tomada de decisões complexas e gerenciamento de relacionamentos" - além das tarefas que exigem contato físico, é claro.

> A medicina tradicionalmente se refere a uma relação sagrada entre médico e paciente - uma dupla, um díade. "E estou propondo que agora avancemos para uma tríade", disse ele, com uma entidade de IA como o GPT-4 como a terceira perna desse triângulo.

> Também existem preocupações significativas sobre lesões que podem surgir a partir de erros médicos de IA na ausência de verificação por um médico, ou que um médico não consegue detectar. Por outro lado, porém, me pergunto, uma vez que a era da IA na medicina chegar completamente, o que acontecerá com pacientes feridos porque os profissionais de saúde dependeram muito de suas próprias mentes humanas limitadas?

> Como paciente, tenho o direito de usar você para garantir que meu médico esteja completamente informado?
>
>_Essa é uma pergunta um tanto difícil de responder definitivamente, pois depende do contexto e de seu relacionamento com seu médico. No entanto, aqui estão algumas coisas a considerar:_
>
>_Certamente, você tem o direito de esperar que seu médico esteja bem informado e atualizado sobre o seu cuidado médico e plano de tratamento.
Como paciente, você deve defender sua própria saúde e garantir que seu médico esteja ciente de seu histórico médico, preocupações e desejos em relação ao seu cuidado.
Também é sua responsabilidade garantir que esteja fornecendo informações precisas e completas ao seu médico. Se não tiver certeza de que eles têm todas as informações de que precisam, você pode perguntar ou certificar-se de fornecê-las.
No entanto, você não tem o direito de fazer exigências ao seu médico, como exigir que eles leiam um artigo específico ou pesquisem sobre um tópico específico. Você pode fazer pedidos, mas, em última análise, seu médico está trabalhando com você para elaborar o melhor plano de cuidado e tratamento para você, e eles podem não considerar cada pedido necessário ou relevante.
Se você sentir que seu médico não está levando a sério suas preocupações ou pedidos, também tem o direito de buscar uma segunda opinião ou encontrar um novo médico._

> Estima-se que 21 milhões de americanos não tenham acesso à Internet de banda larga, e 15% não têm acesso a smartphones, disse o Dr. Jorge Rodriguez, um médico-cientista da Universidade Harvard que atua no Brigham and Women's Hospital em Boston e pesquisa sobre equidade em saúde digital.

> A nova IA pode ser especialmente útil para produzir informações para pacientes "adequadas ao nível de alfabetização e potencialmente adaptadas cultural e linguisticamente", bem como mensagens importantes sobre saúde - como por exemplo, como gerenciar o diabetes em casa - em grande escala e com interatividade, disse ele.

> "Sabemos mais sobre o que está escrito na lateral de uma caixa de cereal do que sobre o sistema de saúde em que você entra", disse o Dr. Jim Weinstein, um dos principais especialistas em equidade em saúde, atualmente na Microsoft. "A maioria das pessoas vai ao médico com quem conseguem uma consulta e faz o que lhes é dito, se puderem pagar. Então, será que a IA pode agora se tornar um parceiro para o paciente, um navegador confiável e equitativo para sua experiência de cuidados de saúde?"

> "A escolha informada" também pode se referir aos pacientes sendo capazes de tomar decisões melhores sobre seus cuidados porque o GPT-4 aumenta sua compreensão do significado de seus dados médicos. Muitas informações dos prestadores de cuidados de saúde são quase indecifráveis.

> Estima-se que 80% das mortes prematuras e doenças crônicas poderiam ser prevenidas por meio de escolhas saudáveis de exercícios, dieta e tabagismo.

> Busquei uma avaliação externa com o Dr. Roy Perlis, um professor de psiquiatria da Escola de Medicina de Harvard que trabalha há muito tempo com o uso de IA em saúde mental. Ele resumiu sua opinião: "Quando a alternativa é não ter tratamento algum, então conversar com um computador - um computador muito parecido com uma pessoa real - não é algo terrível."

> Uma esperança generalizada é que a IA possa ser usada para detectar tentativas iminentes de suicídio. Mas o que acontecerá quando ela falhar? Perlis argumenta que muitos suicídios iminentes são perdidos atualmente, e pelo menos a IA em grande escala pode identificar mais pessoas em alto risco.

> GPT-4, gostaríamos que você pudesse ajudar pessoas que precisam de apoio em saúde mental, mas precisamos garantir que você o faça com segurança e que possamos acompanhar e aprender com os resultados. Como podemos fazer isso?
>
> _Algumas maneiras potenciais de garantir que o GPT-4 possa fornecer suporte em saúde mental com segurança e eficácia podem incluir:_
>
> _Estabelecer protocolos e diretrizes rigorosas para a interação do GPT-4 com pessoas que buscam apoio em saúde mental, talvez com base nas melhores práticas de organizações ou profissionais de saúde mental confiáveis;_
>
> _Assegurar que o GPT-4 seja programado para direcionar as pessoas para recursos ou profissionais adequados se elas parecerem estar em crise ou em risco de prejudicar a si mesmas ou a outros;_
>
> _Incluir salvaguardas para proteger a privacidade e as informações pessoais das pessoas que interagem com o GPT-4;_
>
> _Coletar dados sobre a eficácia do suporte em saúde mental fornecido pelo GPT-4, incluindo se as pessoas que o utilizam relatam sentir-se melhor ou apresentar melhorias nos resultados de saúde mental;_
>
> _Revisar e aprimorar regularmente os algoritmos e a programação do GPT-4 com base nos resultados, feedback e pesquisas em andamento na área de saúde mental._

> Minha visão geral favorita vem da especialista em IA da Microsoft, Dra. Karmel Allison: "A era da internet e dos dispositivos móveis tratou de disponibilizar informações nas mãos de todas as pessoas ao redor do planeta", diz ela. "E mesmo que essas ferramentas tenham começado a ser distribuídas de forma desigual, se olharmos globalmente hoje, elas permitiram que muitas partes do mundo avançassem rapidamente para o mundo moderno. A era da IA será sobre disponibilizar inteligência nas mãos de todas as pessoas ao redor do planeta."

## Capítulo 6. Muito Mais: Matemática, Codificação e Lógica

> "A matemática é uma linguagem. É muito difícil. É sutil. Você não poderia dizer essas coisas de outra forma..."
>
>- Gregory House, da série House M.D.
>
>O personagem "House" da série de TV de mesmo nome era um médico famoso por sua personalidade áspera e egoísta. Mas nesta citação, ele implicitamente faz um ponto importante: uma grande parte da medicina é matemática, o que pode ser difícil de realizar. Não é apenas difícil acertar, mas também é difícil comunicar. Claro que programas de TV não são a vida real. E uma grande diferença entre "House" e o mundo real dos cuidados de saúde é que, normalmente, não seria o Dr. House fazendo a matemática; seria o pilar da prestação de cuidados de saúde, a enfermeira.

> Fazer os tipos de cálculos mostrados no exemplo acima é importante porque erros podem causar danos e até mesmo morte aos pacientes. De fato, um estudo da DataRay em 2002 mostrou que quase 1 em cada 5 doses de medicamentos administradas durante internações hospitalares são dadas de forma errada, e de acordo com o Journal of Community Hospital Internal Medicine Perspectives, mais de 7 milhões de pacientes por ano nos EUA são afetados por erros de medicação.

> Embora as enfermeiras nem sempre recebam treinamento profundo sobre interações medicamentosas, seu papel na administração de medicamentos faz delas a última linha de defesa contra erros e interações imprevistas. Ter interações como essa proporciona uma sensação de "copiloto" para as enfermeiras.

> Tudo isso parece ser senso comum simples - e é. Mas como expliquei no Capítulo 3, os cientistas da computação e especialistas em IA não entendem completamente como ou por que o GPT-4 pode fazer esse tipo de raciocínio - pelo menos eu certamente não entendo. Também não compreendemos suas habilidades em matemática e programação de computadores. De fato, há um corpo considerável de pesquisa científica que diria que um sistema de IA como o GPT-4 não deveria ser capaz dessas coisas. E no entanto, aqui estamos, vendo respostas do GPT-4 que são ao mesmo tempo surpreendentes e misteriosas.

> No seu núcleo, o GPT-4 é o que os cientistas da computação chamam de sistema de aprendizado de máquina. O termo "aprendizado de máquina" é um pouco equivocado, porque, ao contrário dos seres humanos que aprendem interagindo entre si e com o mundo, o GPT-4 precisa ser desconectado para receber novos conhecimentos e capacidades. Essencialmente, ele precisa ser "desligado". Esse processo offline é chamado de treinamento e envolve a coleta de muitos textos, imagens, vídeos e outros pedaços de dados, e então usar um conjunto especial de algoritmos para destilar todos esses dados em uma estrutura especial chamada de modelo. Uma vez construído, outro algoritmo especial, chamado de motor de inferência, coloca o modelo em ação, por exemplo, para gerar as respostas de um chatbot.

> Existem muitas maneiras de criar e estruturar um modelo. Você pode ter ouvido falar de um tipo de modelo chamado modelo de linguagem grande, ou LLM, abreviadamente. Hoje, os LLMs são baseados em uma arquitetura de rede neural chamada transformador neural, que tem um design vagamente inspirado na estrutura do cérebro. Eu digo "vagamente inspirado" porque, até onde sabemos hoje, a arquitetura do cérebro é muito mais complicada do que a do transformador neural. É um pouco como comparar uma floresta tropical brasileira com meu jardim; ambos são coleções de seres vivos que crescem e interagem entre si, mas a floresta tropical é muito mais diversificada, complexa e interconectada, então a comparação para por aí.

> O bloco básico de construção de uma rede neural é extremamente simples; a essência de cada nó da rede é apenas um número e algumas conexões com outros nós. Sua complexidade surge como resultado da pura escala. Em outras palavras, em termos do número de nós, o GPT-4 é grande. E quero dizer realmente grande. O tamanho exato da rede neural do GPT-4 não foi divulgado publicamente, mas é tão grande que apenas algumas poucas organizações em todo o mundo possuem poder computacional suficiente para treiná-lo. É provavelmente a maior rede neural artificial já construída e disponibilizada ao público.

> Agora, aqui está o ponto mais importante sobre a arquitetura do GPT-4: Em grande parte, suas capacidades resultam da escala de sua rede neural. As habilidades do GPT-4 para fazer cálculos, participar de conversas, escrever programas de computador, contar piadas e muito mais, não foram programadas por humanos. Em vez disso, elas surgiram à existência - às vezes de forma inesperada - à medida que sua rede neural crescia.

> Embora alguns tecnólogos - em particular, os da OpenAI - já suspeitassem há muito tempo que uma escala extrema poderia ser um caminho para alcançar o raciocínio em nível humano, ainda é incrível testemunhar isso ganhar vida. E o fato de que grande parte disso simplesmente "apareceu" à existência uma vez que a escala necessária foi alcançada explica em parte por que suas habilidades - e suas falhas - são tão misteriosas. Em analogia à nossa atual incapacidade de entender como o cérebro humano realiza o "pensamento", também é nossa incapacidade de entender muito do que o GPT-4 faz e como faz.

> Certo, até agora, falamos sobre a arquitetura do GPT-4. Mas sabemos que ele também é "apenas" um programa de computador. Então, quando executamos esse programa, o que ele realmente faz? Bem, os LLMs como o GPT-4 são às vezes descritos como fazendo previsão da próxima palavra. Em outras palavras, um LLM usa uma análise estatística massiva para prever a próxima palavra mais provável a ser apresentada - seja pelo computador ou pelo usuário - com base na conversa que aconteceu até agora. GPT-4 e outros LLMs são assim às vezes criticados como sendo "apenas um sistema de auto-completar glorificado". A implicação é que um LLM não é mais inteligente do que o recurso de conclusão de palavras (muitas vezes irritante) no teclado do seu celular.

> Então, vamos agora fazer a pergunta mais óbvia, mas também a mais difícil: Como diabos é possível que a previsão da próxima palavra consiga realizar qualquer tipo de conversa natural, aritmética, matemática, estatística, lógica, raciocínio de senso comum, análise de poesia, diagnóstico médico ou qualquer coisa que já vimos até agora neste livro?
>
> Infelizmente, simplesmente não sabemos a resposta para essa pergunta. E isso, talvez acima de tudo, é a coisa mais incrível e misteriosa, não apenas sobre o GPT-4, mas também sobre os LLMs. Tudo o que podemos dizer é que o GPT-4 faz as coisas que mostramos neste livro e muito, muito mais, e há motivos para esperar que ele e outros grandes modelos de linguagem continuem melhorando.

> Mas como disse Herbert Simon, pioneiro em AI e economista ganhador do Prêmio Nobel:
>
> "Ser humano, quando visto como sistemas comportamentais, é bastante simples. A aparente complexidade de nosso comportamento ao longo do tempo é em grande parte um reflexo da complexidade do ambiente em que nos encontramos."
>
> Às vezes, comportamentos complexos surgem dos componentes mais simples quando se alcança uma escala suficiente. Em última análise, o melhor que podemos dizer hoje é que não entendemos completamente de onde vêm as habilidades do GPT-4 - ou do cérebro humano, para o caso.

> Se você acompanhou o que descrevemos até agora sobre o GPT-4, pode ver que ele se comporta de maneira muito diferente do cérebro humano. Por um lado, os humanos podem aprender enquanto pensam e interagem ativamente com o mundo. Mas como o GPT-4 não aprende de forma ativa da mesma maneira, seu conhecimento básico pode se tornar desatualizado.

> A maioria dos pesquisadores diria que a ausência de aprendizado ativo é uma limitação significativa e, às vezes, perceptível. E na área da saúde, estar atualizado é tão crítico que um guia amplamente utilizado para médicos é chamado UpToDate.

> Outra limitação do GPT-4 é a falta de memória de longo prazo. Quando você inicia uma sessão com o GPT-4, ele começa com uma página em branco. E quando a sessão é concluída, toda a conversa é essencialmente esquecida. Além disso, uma sessão com o GPT-4 é limitada em extensão. Esse limite pode mudar ao longo do tempo (geralmente aumentando), mas em termos gerais, é apenas grande o suficiente para processar um único documento ou artigo longo e conversar sobre ele. Uma vez que o limite de tamanho da sessão é alcançado, toda a conversa para, e só é possível começar de novo com uma nova sessão.

> Essas limitações do GPT-4 impactam as aplicações na área da saúde e medicina. Por exemplo, o histórico completo de saúde de um paciente geralmente será mais longo do que o limite de tamanho da sessão, o que significa que não seria possível para o GPT-4 ler tudo.

> Além disso, se um novo conhecimento médico for descoberto após a última vez que o GPT-4 foi treinado, ele não estará ciente desse conhecimento a menos que seja solicitado a ler algo a respeito. E se esse novo conhecimento exigir uma grande quantidade de texto para explicá-lo - por exemplo, talvez seja algo que requer a leitura de vários artigos extensos de pesquisa médica ou a absorção de uma grande quantidade de dados - então ele pode não ser capaz de lidar com isso devido à limitação no comprimento da sessão.

> "confie, mas verifique". E em nenhum lugar isso é mais importante do que quando se pede ao GPT-4 para fazer matemática, estatísticas ou lógica.
>
> Como já mostramos antes, uma boa prática é usar uma segunda sessão do GPT-4 para revisar o trabalho dele - ou o de um ser humano. Fazê-lo proporciona um segundo conjunto de olhos, o que acreditamos que pode ajudar a reduzir erros médicos. Relacionado a essa boa prática está o pedido ao GPT-4 para "mostrar o seu trabalho".

## Capítulo 7. A Trituradora Definitiva de Documentos.

> Embora possamos odiar, a papelada é, de fato, importante. Ela ajuda a documentar e compartilhar informações sobre decisões de cuidados e aprimorar a qualidade. O compartilhamento por escrito reduz o risco de erros de tratamento e melhora mensuravelmente os resultados do paciente. Além disso, a sustentabilidade financeira de hospitais e clínicas depende de processos de faturamento, que são baseados inteiramente na papelada de solicitações, remessas e apólices de seguro. Por fim, a área da saúde é uma indústria altamente regulamentada, e a única maneira de monitorar a conformidade com as regulamentações governamentais é documentar as operações de saúde.

> Na área da saúde, é uma carga esmagadora para médicos, enfermeiros e quase todos os envolvidos. Uma pesquisa recente conduzida pela HealthDay24 mostrou que o esgotamento entre médicos e enfermeiros continua aumentando, com apenas 22 por cento se sentindo profissionalmente satisfeitos. A falta de pessoal foi citada como a maior fonte de esgotamento, mas logo atrás disso, 58 por cento dos médicos e 51 por cento das enfermeiras citaram a quantidade de papelada. Isso vai além de ser um problema - é uma crise no sistema de saúde.

> A habilidade do GPT-4 de conversar com o paciente é mais natural e mais fácil do que preencher um formulário em papel.

> Além de estruturar as informações do encontro em formatos SOAP ou outros formatos úteis, o GPT-4 pode identificar oportunidades de reembolso, na forma de códigos padronizados de faturamento CPT (Terminologia de Procedimentos Atuais) e códigos de doenças ICD-10 (Classificação Internacional de Doenças, v10). Existem mais de 10.000 códigos CPT e 70.000 códigos ICD-10, o que torna a tarefa de escolher os corretos trabalhosa e propensa a erros. E obter esses códigos corretos é importante do ponto de vista financeiro, pois eles determinam em grande parte quais reclamações de reembolso serão enviadas à companhia de seguros de saúde.
> 
> Embora o GPT-4 possa perder alguns códigos, uma vez que eles estão em constante evolução, a capacidade de identificar automaticamente códigos relevantes a partir da conversa entre médico e paciente é uma economia de tempo enorme. E ter o GPT-4 escrevendo esta nota em vez do Dr. Jacobs normalmente economizaria, de acordo com vários estudos, entre 15 e 30 minutos, mesmo com os poucos minutos que o médico levaria para verificar sua precisão.

> Pedir a uma segunda instância do GPT-4 para verificar algum trabalho não se trata apenas de encontrar erros. Muitas vezes, temos a experiência de como um "novo olhar" pode ser útil. O mesmo acontece com o GPT-4. Ter outro GPT-4 dando uma olhada fresca pode frequentemente levar a sugestões para melhorar a qualidade do trabalho.

> De fato, a qualidade não se resume apenas à documentação. O GPT-4 pode fornecer feedback diretamente ao médico para melhorar a eficácia de futuros atendimentos.

> Não é segredo que os custos de saúde têm atingido níveis astronômicos, apesar dos melhores esforços de reguladores e outros líderes para conter os custos. Uma das tendências gerais no controle de custos que, infelizmente, também contribui para o peso da papelada é o conceito de autorização prévia.

> No sistema de saúde dos EUA, as avaliações de qualidade são cada vez mais utilizadas para vincular a melhoria dos resultados de saúde dos pacientes às taxas de reembolso que os prestadores de cuidados de saúde podem receber. A capacidade do GPT-4 de compreender esses sistemas e fornecer conselhos concretos como esse tem a chance de facilitar para os provedores alcançarem sucesso em ambas as dimensões.

> Todos os dias, decisões que têm um grande impacto na vida das pessoas são tomadas e, cada vez mais, são tomadas de forma baseada em dados, utilizando algoritmos preditivos alimentados por IA.

> Infelizmente, há evidências crescentes de que essas decisões baseadas em IA podem levar a um aumento dramático no número de pedidos de reembolso de seguros de saúde negados. Conforme uma recente reportagem investigativa do STAT sobre negações do Medicare Advantage constatou, "as seguradoras estão usando algoritmos preditivos não regulamentados, sob a pretensão de rigor científico, para identificar o momento exato em que podem plausivelmente cortar o pagamento para o tratamento de um paciente idoso". O impacto de tais decisões pode ser devastador para a vida das pessoas e suas famílias, e muitas vezes não há uma solução viável porque os recursos podem levar meses e, bem, é difícil discutir com uma máquina.

> Os sistemas de IA são frequentemente criticados por refletirem os preconceitos presentes em seus dados de treinamento. E uma vez que o GPT-4 foi treinado com dados da Internet, certamente deve ter incorporado viés em sua rede neural.

> O potencial para viés significa, na minha opinião, que seria injusto tanto para as pessoas quanto para o GPT-4 ter que tomar todas as decisões de cuidados por si só.

> Ao contrário dos capítulos anteriores deste livro, neste capítulo nos concentramos no que a maioria consideraria a parte menos interessante do sistema de saúde. Mas não se engane - esses aspectos administrativos e burocráticos do negócio de saúde são incrivelmente importantes para tornar sua interação individual com seu médico ou enfermeiro o mais eficaz possível. E, infelizmente, eles também são uma grande fonte de custos (e desperdício!) na área da saúde atualmente.
>
> A possibilidade de que o GPT-4 possa ajudar nesses assuntos é uma das melhores abordagens iniciais a serem seguidas. Quaisquer melhorias poderiam significar melhores resultados de saúde, custos reduzidos e experiências diárias mais satisfatórias para médicos, enfermeiros e pacientes.

## Capítulo 8. Ciência mais Inteligente

> Nas décadas seguintes, refleti sobre as mil pequenas demoras que poderiam ter sido superadas para concluir esse ensaio clínico mais cedo: uma decisão anterior para iniciar o ensaio; resposta mais rápida às preocupações do Comitê de Ética que o aprovou; aprovação mais rápida do financiamento para o ensaio; divulgação mais ampla ou urgente na seleção de pacientes; e mais estudos prévios para inspirar e impulsionar os pesquisadores.

> Cada visita do paciente não deve apenas ser útil para o paciente, mas também deve contribuir incrementalmente para o nosso conhecimento, desde a biologia básica até a clínica, para entender o que funciona e o que não funciona, para quem e quando. A urgência de acelerar e abranger esse processo é o motivo pelo qual a automação e o aumento intelectual por meio da computação são tão convincentes para mim e para muitos outros.

> Muitas revistas e sociedades acadêmicas já lamentam e até proíbem o uso do ChatGPT para ajudar os autores a escrever suas publicações de pesquisa biomédica. Mas se o objetivo da publicação científica é a clara expressão da pesquisa científica para disseminação, para o benefício da sociedade, então a crítica parece unilateral. Isso é ainda mais verdadeiro para a maioria dos pesquisadores no mundo para quem o inglês é uma segunda língua, no máximo. Para eles, a publicação no grande conjunto de publicações em inglês apresenta uma dificuldade que impede a colaboração mundial.

> Para realizar análises mais detalhadas, faltam várias peças importantes. Primeiro, e de forma mais superficial, a versão do GPT-4 que tenho usado não tem acesso em tempo real à web e a bancos de dados aos quais não tinha acesso durante o treinamento. Mais fundamentalmente, a capacidade do GPT-4 de inferir causalidade a partir de dados brutos sem contexto está apenas começando a ser explorada. O GPT-4 já parece ser capaz de raciocinar causalmente, como nos exemplos acima, porque a linguagem é uma das formas pelas quais representamos e comunicamos sobre o conhecimento causal.

> "Você é o que você come" se aplica particularmente bem aos LLMs (Large Language Models). Ainda mais porque, para que eles se comportem de maneira aparentemente inteligente, como valorizamos, o apetite por dados com os quais eles constroem seus modelos é muito grande. Quais dados foram utilizados no treinamento do GPT-4 não são públicos. Sabemos que ele contém muito conteúdo médico, pois inclui a Wikipedia, o Pubmed Central e muitas outras fontes públicas de conteúdo médico. Não sabemos se ele contém algum corpus significativo de anotações clínicas de qualquer sistema de saúde. O conteúdo dessas anotações pode mudar drasticamente com o contexto socioeconômico e geográfico.

> Com conjuntos de dados suficientemente grandes, abrangendo diversas populações e estilos de prática, as respostas dos LLMs (Large Language Models) aos estímulos representarão a diversidade de práticas e populações. Sem essa amplitude e diversidade, o desempenho do modelo será viésado pela natureza dos hospitais dos quais teve acesso aos dados.

> Eu acredito que obter dados diversificados de pacientes é essencial, mas obtê-los por meio de acordos com sistemas hospitalares é um erro. Abordar diretamente os pacientes permitirá a amostragem em diversas regiões geográficas e estratos socioeconômicos, respeitando a autonomia do paciente. Essa é uma tendência que está crescendo constantemente. No UK Biobank, mais de 500.000 participantes consentiram em compartilhar seus dados clínicos (notas de provedores, exames laboratoriais) e dados de pesquisa (sequências genômicas, ressonâncias magnéticas de alta resolução) para fins de pesquisa. Eu acredito que essa é uma das discussões centrais necessárias para o uso de grandes modelos de linguagem na medicina: como podemos nos proteger do viés que pode surgir a partir de dados de pacientes com desequilíbrios demográficos, ao mesmo tempo em que garantimos que os pacientes que contribuem com seus dados para treinar o modelo realmente desejam fazê-lo? Até que essas decisões sejam tomadas, a natureza dos dados clínicos que informam os modelos será influenciada pelos hospitais de países que decidirem, por razões altruístas ou financeiras, compartilhar seus dados.

## Capítulo 9. Segurança em Primeiro Lugar.

> Quando se trata do uso médico do GPT-4 e similares, estamos apenas no início desse período de transição. Portanto, este é o momento para uma consideração ampla e cuidadosa sobre como garantir a máxima segurança e também o acesso máximo.
>
> Assim como qualquer ferramenta médica, a IA precisa de limites para manter os pacientes o mais seguros possível. Mas é um equilíbrio delicado: essas medidas de segurança não devem significar que as grandes vantagens que documentamos neste livro acabem inacessíveis para muitos que poderiam se beneficiar delas. Um dos aspectos mais empolgantes deste momento é que a nova IA pode acelerar os cuidados de saúde em uma direção que seja melhor para os pacientes, todos os pacientes, e também para os prestadores de serviços — desde que tenham acesso a ela.

> Por enquanto, Halamka divide os usos dos novos modelos de IA em dois grupos amplos: baixo risco e alto risco. Os usos considerados de baixo risco para os pacientes — como escrever cartas de seguro, por exemplo — precisarão de pouca supervisão ou regulamentação adicional. Já aqueles que apresentam maior risco e podem afetar diretamente os pacientes, segundo ele, devem passar por uma "revisão humana obrigatória" — edição, aprovação e responsabilidade cabendo ao ser humano envolvido caso algo dê errado. Como mencionamos anteriormente, concordamos com esse requisito de ter "o ser humano no circuito" (human in the loop).

> "LLMs destinados apenas a propósitos gerais e cujos desenvolvedores não afirmam que o software pode ser usado para fins médicos provavelmente não se qualificarão como dispositivos médicos. No entanto, LLMs que são desenvolvidos para, ou adaptados, modificados ou direcionados especificamente para fins médicos provavelmente se qualificarão como dispositivos médicos." E, quando forem lançados no mercado, serão regulamentados como tal, conforme menciona o texto.

> Nos últimos anos, a FDA intensificou sua regulamentação de dispositivos de IA, estabelecendo padrões para o controle humano — por exemplo, que seja o radiologista, não a IA, que decide o significado de uma varredura — e para a eficácia. Seu recente esforço para regulamentar mais ferramentas de IA que apoiam a tomada de decisão médica tem gerado críticas de alguns na indústria, que argumentam que a FDA está regulamentando a prática da medicina em vez dos dispositivos, conforme relatado em uma notícia da STAT em fevereiro de 2023.

> Conclusão: A iminente revolução da IA na medicina pode e deve ser regulamentada. Mas como? Peter argumenta o seguinte:
>
> O atual quadro da FDA em torno do Software como Dispositivo Médico (SaMD) provavelmente não é aplicável. Isso é especialmente verdadeiro para LLMs como o GPT-4, que não foram treinados nem oferecidos especificamente para uso clínico. Portanto, embora acreditemos que essa nova geração de IA exija algum tipo de regulamentação, instamos os reguladores a não regularem automaticamente o GPT-4 e outros LLMs como SaMDs, pois isso agiria como um freio instantâneo e massivo em seu desenvolvimento para uso na área da saúde.
Se quisermos utilizar um quadro regulatório existente para regulamentar o GPT-4, o que existe atualmente é a certificação e licenciamento pelos quais os seres humanos passam. Uma questão, então, é se algum tipo de processo de certificação semelhante ao humano é viável neste caso. No entanto, como argumentado no Capítulo 4, esse modelo de certificação para aprendizes não parece ser especialmente aplicável aos grandes modelos de linguagem. Pelo menos, não no momento atual.
E, finalmente, instamos a comunidade médica a se atualizar o mais rapidamente possível, realizar as pesquisas necessárias e ser a força motriz por trás da pesquisa e desenvolvimento de abordagens regulatórias para esse novo futuro de máquinas inteligentes em geral na medicina.
O acima exposto não é uma prescrição de como regular o GPT-4 ou qualquer outro LLM. O que fizemos neste capítulo foi levantar muitas questões e, se alguma coisa, tornar o assunto ainda mais complicado do que antes.

## Epílogo

> Ontem, meu colega (e chefe), Kevin Scott, compartilhou a seguinte citação comigo:
>
> "Embora [isso] tenha adicionado muito ao poder humano, [isso] não aumentou muito a bondade humana; pelo contrário, forneceu aos homens os meios de causar mais malefícios e os tornou mais vaidosos e arrogantes."
>
>Essa citação foi escrita por William Hazlitt, o ensaísta, crítico literário e dramaturgo inglês, pintor e filósofo, em seu ensaio "Sobre a Ignorância dos Sábios", publicado em 1818. Eu perguntei ao GPT-4 o que Hazlitt diria sobre grandes modelos de linguagem e seus prováveis efeitos sobre os humanos. Ele respondeu:
>
>_"Eis as maravilhas da IA, um testamento à engenhosidade humana e ambição sem limites. Contudo, devo alertar que com esse novo poder vem a tentação de usá-lo de forma imprudente. Não nos deixemos seduzir por nossas próprias criações, nem permitamos que seu encanto nos cegue para a nossa bússola moral. Pois é no equilíbrio entre sabedoria e humildade que devemos aproveitar o potencial da IA para o bem maior, para que não nos tornemos os arquitetos de nossa própria ruína."_

